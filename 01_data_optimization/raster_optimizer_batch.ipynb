{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster optimizer\n",
    "- We want to import some rasters inside and make them all full optimized\n",
    "- Here we cover all the possible issues we could get from a raster layer\n",
    "- The process gives an optimized raster as an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script goes for every tif file in a folder\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from sys import path\n",
    "from osgeo import gdal, gdalconst\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"input and output\"\"\"\n",
    "path = r\"C:\\Users\\admin\\Downloads\\treecover_2000\"\n",
    "output_path = path + \"\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raster_file_list(path):\n",
    "    \"\"\"Get a list of the raster files inside the folder\"\"\"\n",
    "    File_list = [] #f for f in os.listdir(path) if os.isfile(mypath,f)\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".tif\") or file.endswith(\".tiff\"):\n",
    "            if file not in File_list:\n",
    "                File_list.append(os.path.join(path,file))\n",
    "        else:\n",
    "            pass\n",
    "    return File_list\n",
    "\n",
    "def create_output_folder(output_path):\n",
    "    \"\"\"Create the output folder\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        print(\"created the output folder\")    \n",
    "        return os.mkdir(output_path)\n",
    "    else:\n",
    "        return print(\"there is already an output folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_dtype(raster_path, block_size=1024):\n",
    "    # Open the raster dataset\n",
    "    dataset = gdal.Open(raster_path)\n",
    "    if dataset is None:\n",
    "        raise ValueError(\"Unable to open the raster file.\")\n",
    "\n",
    "    # Get raster properties\n",
    "    num_cols = dataset.RasterXSize\n",
    "    num_rows = dataset.RasterYSize\n",
    "    num_bands = dataset.RasterCount\n",
    "    if num_bands > 1:\n",
    "        raise ValueError(\"You weren't ready for this.\")\n",
    "\n",
    "    # Analyze the range of values and determine the optimal data type\n",
    "    min_val = None\n",
    "    max_val = None\n",
    "\n",
    "    for y in range(0, num_rows, block_size):\n",
    "        rows = min(block_size, num_rows - y)\n",
    "        for x in range(0, num_cols, block_size):\n",
    "            cols = min(block_size, num_cols - x)\n",
    "\n",
    "            # Read a block of raster data\n",
    "            block_data = dataset.ReadAsArray(x, y, cols, rows)\n",
    "\n",
    "            # Get unique values and update min_val and max_val\n",
    "            unique_values = np.unique(block_data)\n",
    "            if min_val is None:\n",
    "                min_val = np.min(unique_values)\n",
    "                max_val = np.max(unique_values)\n",
    "            else:\n",
    "                min_val = min(min_val, np.min(unique_values))\n",
    "                max_val = max(max_val, np.max(unique_values))\n",
    "\n",
    "    dtype = None\n",
    "\n",
    "    if np.issubdtype(block_data.dtype, np.integer):\n",
    "        if min_val >= 0:\n",
    "            if max_val <= 255:\n",
    "                dtype = gdal.GDT_Byte\n",
    "            elif max_val <= 65535:\n",
    "                dtype = gdal.GDT_UInt16\n",
    "            else:\n",
    "                dtype = gdal.GDT_Int32\n",
    "        else:\n",
    "            if min_val >= -32768 and max_val <= 32767:\n",
    "                dtype = gdal.GDT_Int16\n",
    "            else:\n",
    "                dtype = gdal.GDT_Int32\n",
    "    else:\n",
    "        # Floating-point data\n",
    "        dtype = gdal.GDT_Float32\n",
    "\n",
    "    return dtype\n",
    "\n",
    "def convert_data_type(input_raster, output_raster, data_type, nodata_value):\n",
    "    dataset = gdal.Open(input_raster)\n",
    "    if dataset is None:\n",
    "        raise ValueError(\"Unable to open the input raster file.\")\n",
    "    \n",
    "    band = dataset.GetRasterBand(1)\n",
    "\n",
    "    if not data_type:\n",
    "        print(\"Get the data type\")\n",
    "        data_type = band.DataType\n",
    "\n",
    "    # Remove the color table and Set the ColorInterp to Gray\n",
    "    band.SetRasterColorTable(None)\n",
    "    band.SetColorInterpretation(gdalconst.GCI_GrayIndex)\n",
    "\n",
    "    # get the projection\n",
    "    projection = dataset.GetProjection()\n",
    "\n",
    "    # Create the output raster dataset with the desired data type\n",
    "    gdal.Warp(output_raster, \n",
    "              dataset, \n",
    "              outputType=data_type, \n",
    "              dstSRS=projection, \n",
    "              dstNodata=nodata_value, \n",
    "              creationOptions = [\"TILED=YES\",\"COMPRESS=DEFLATE\",'COPY_SRC_OVERVIEWS=YES'])\n",
    "\n",
    "    # Close the datasets\n",
    "    dataset = None\n",
    "    return print(\"finished with: \" + output_raster)\n",
    "\n",
    "def create_overviews(raster):\n",
    "    dataset = gdal.Open(raster, gdal.GA_Update) # GA_Update is used when we want to do modification on the raster\n",
    "    if dataset:\n",
    "        # Get the first raster band (assuming single-band raster)\n",
    "        band = dataset.GetRasterBand(1)\n",
    "\n",
    "        # Check if the band has overviews\n",
    "        if band.GetOverviewCount() > 0:\n",
    "            print(\"Raster band already has overviews.\")\n",
    "        else:\n",
    "            # Build overviews using multiple overview levels (2x, 4x, 8x, etc.)\n",
    "            overview_levels = [2, 4, 8]\n",
    "            dataset.BuildOverviews(\"average\", overview_levels)\n",
    "            print(\"Overviews built successfully.\")\n",
    "\n",
    "        dataset = None  # Close the dataset\n",
    "    else:\n",
    "        print(\"Failed to open the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_list = get_raster_file_list(path)\n",
    "nodata_value = 255\n",
    "print(File_list)\n",
    "create_output_folder(output_path)\n",
    "\n",
    "rule = \"don't calculate optimal\" # Habr√° que mejorar esto\n",
    "\n",
    "for file in File_list[:]:\n",
    "    print(file)\n",
    "    # get the file name\n",
    "    filename = os.path.basename(file)\n",
    "    # split the filename by the dot and add a sufix\n",
    "    output_filename = os.path.splitext(filename)[0] + \".tif\"\n",
    "    #build the output path + new filename\n",
    "    output_file = os.path.join(output_path,output_filename)\n",
    "    # get the optimal file type\n",
    "    if not rule:\n",
    "        dtype = get_optimal_dtype(file)\n",
    "        # convert_data_type(file, output_file, dtype)\n",
    "        \n",
    "    print(\"no need to optimize\")\n",
    "    convert_data_type(file, output_file, dtype, nodata_value)\n",
    "    \n",
    "print(\"Raster data type optimization completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create the overviews if neccesary\"\"\"\n",
    "File_list = get_raster_file_list(output_path)\n",
    "\n",
    "for file in File_list[:]:\n",
    "    create_overviews(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some personal testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "#This iterates for every file in the directory\n",
    "for file in File_list[:]:\n",
    "    print(file)\n",
    "    dataset = gdal.Open(file)\n",
    "\n",
    "    \"\"\"This part is just for testing, it is not really neccesary of this case.\n",
    "     This is a way to get the Metadata of the raster (If the raster is big It can take more than 2mins)\"\"\"\n",
    "    stats =  dataset.GetRasterBand(1).GetStatistics(0,1) #it will return a list(Min, Max, Mean, StdDev)\n",
    "    Metadata_domain = dataset.GetMetadataDomainList() #From here we get the 'IMAGE_STRUCTURE'\n",
    "    image_structure = dataset.GetMetadata('IMAGE_STRUCTURE') #here inside\n",
    "\n",
    "    \"\"\"The file is too big to read it into a single array, so we are going to split into different ones\"\"\"\n",
    "\n",
    "    \"\"\"Here we get the size of the file\"\"\"\n",
    "    width = dataset.RasterXSize #columns\n",
    "    height = dataset.RasterYSize #rows\n",
    "\n",
    "    # define your tile size\n",
    "    # it could be 256,512 or 1024. it depends on your scope\n",
    "    tilesize = 10000\n",
    "\n",
    "    unique_values_list = []\n",
    "\n",
    "    \"\"\"Here we start with the tiling to\"\"\"\n",
    "    for i in range(0, width, tilesize)[0:1]: #tilesize marks from where to where in width\n",
    "        w = min(i+tilesize, width) - i\n",
    "        for j in range(0, height, tilesize)[0:1]: #tilesize in height\n",
    "            #for the edge parts, so we don't get nodata from the borders\n",
    "            h = min(j+tilesize, height) - j\n",
    "            try:\n",
    "                ds = gdal.Translate(\"\",\n",
    "                dataset, \n",
    "                format = 'MEM', \n",
    "                # noData = -32768,\n",
    "                # outputType = gdal.GDT_Int16, \n",
    "                # creationOptions = ['COMPRESS=DEFLATE','TILED=YES','COPY_SRC_OVERVIEWS=YES'],\n",
    "                srcWin = [str(i), str(j), str(w), str(h)])\n",
    "                print(\"the dataset is: \", ds)\n",
    "\n",
    "                band =  ds.GetRasterBand(1)\n",
    "                array = np.array(band.ReadAsArray())\n",
    "                values = np.unique(array)\n",
    "                for x in values:\n",
    "                    print (x)\n",
    "                    if x not in unique_values_list:\n",
    "                        unique_values_list.append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "                ds = None\n",
    "            except RuntimeError:\n",
    "                print(\"The script got an error\")\n",
    "                sys.exit(1)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's over the optimization\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tenemos que comprobar que los datos sean Categoricos o contiugos\n",
    "Para categoricos habria que hacer el vecino proximo\n",
    "Para continuos habr√≠a que hacerlo Bicubica - Bilineal\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#This iterates for every file in the directory\n",
    "for file in os.listdir(path)[0:1]:\n",
    "    #un landcover al ser una classificacion tendra valores tipo int (NearestNeightbour), los valores tipo real son mas para elevaciones, distancias etc (bilineal)\n",
    "\n",
    "    # resampleAlg = gdal.GRIORA_NearestNeighbour\n",
    "    # resampleAlg = gdal.GRIORA_Bilinear\n",
    "    # esto a√±adelo al final\n",
    "\n",
    "    #we concatenate the path\n",
    "    input = path +\"/\"+ file\n",
    "    output = out + '/' + file.replace(\".tif\",\"\") + \"_optimized.tif\"\n",
    "    #here is the GDAL transformation, we set the path + / + variable\n",
    "    \n",
    "    # gdal.Warp(output, input, creationOptions = ['COMPRESS=' + str(compression)], dstSRS = \"EPSG:4326\")\n",
    "    gdal.Translate(output, input, creationOptions = ['COMPRESS=DEFLATE','TILED=YES','BLOCKXSIZE=128','BLOCKYSIZE=128'])\n",
    "    \n",
    "\n",
    "    ds = gdal.Open(output, 1)\n",
    "    band = ds.GetRasterBand(1)\n",
    "    band.SetRasterColorTable(None) # this works and deletes the color pallete\n",
    "    # band.DestroyColorTable() #another option\n",
    "\n",
    "    #set the data type\n",
    "\n",
    "\n",
    "    del band, ds\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"It's over the optimization\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea83a5ad54c8cc9e7ff8f4ab9d2bf25c75f7997df51cce98e5453f4f3fcc4a0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
